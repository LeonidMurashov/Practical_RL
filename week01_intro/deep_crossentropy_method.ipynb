{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://watanimg.elwatannews.com/old_news_images/large/249765_Large_20140709045740_11.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\r\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probability of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        s = s[None]\n",
    "        probs = agent.predict_proba(s)[0]\n",
    "\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(np.arange(len(probs)), p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-7dea09684861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdummy_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"states:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"actions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reward:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-a1889534d865>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"make sure probabilities are a vector (hint: np.reshape)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \"\"\"\n\u001b[1;32m   1071\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 2)"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    \n",
    "    states_batch = np.array(states_batch, dtype=object)\n",
    "    actions_batch = np.array(actions_batch, dtype=object)\n",
    "    rewards_batch = np.array(rewards_batch, dtype=object)\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile) #<YOUR CODE: compute minimum reward for elite sessions. Hint: use np.percentile()>\n",
    "    elite_states = states_batch[rewards_batch >= reward_threshold]\n",
    "    elite_actions = actions_batch[rewards_batch >= reward_threshold]\n",
    "    elite_states = np.concatenate(elite_states)\n",
    "    elite_actions = np.concatenate(elite_actions)\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 202.700, threshold=232.900\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bf93c6c6fff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-bf93c6c6fff1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dc1e3ad5a73b>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# use the probabilities you predicted to pick an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# sample proportionally to the probabilities, don't just take the most likely action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# ^-- hint: try np.random.choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(env, agent) for i in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    \n",
    "    agent.partial_fit(elite_states[:, 0], elite_actions)\n",
    "        \n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.56214.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "video_path = video_paths[-1]  # You can also try other indices\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # https://stackoverflow.com/a/57378660/1214547\n",
    "    with video_path.open('rb') as fp:\n",
    "        mp4 = fp.read()\n",
    "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "else:\n",
    "    data_url = str(video_path)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(data_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (2 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`. Provide here some figures so we can see how the hyperparameters influence the performance.\n",
    "- __1.2__ (1 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment, you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: `MountainCar-v0` or `LunarLander-v2`.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get some of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (up to 6 pts) Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [`joblib`](https://joblib.readthedocs.io/en/latest/). However, note that you will probably need to spawn a new environment in each of the workers instead of passing it via pickling. (2 pts)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training. (2 pts)\n",
    "  * Obtain __-100__ at `MountainCar-v0` or __+200__ at `LunarLander-v2` (2 pts). Feel free to experiment with hyperparameters, architectures, schedules etc.\n",
    "  \n",
    "__Please list what you did in Anytask submission form__. This reduces probability that somebody misses something.\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails to cut off bad sessions__ while R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it doesn't train, it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_mountain_car(env, agent):\n",
    "#     # Compute policy for all possible x and v (with discretization)\n",
    "#     xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "#     vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    \n",
    "#     grid = np.dstack(np.meshgrid(xs, vs[::-1])).transpose(1, 0, 2)\n",
    "#     grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "#     probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3).transpose(1, 0, 2)\n",
    "\n",
    "#     # # The above code is equivalent to the following:\n",
    "#     # probs = np.empty((len(vs), len(xs), 3))\n",
    "#     # for i, v in enumerate(vs[::-1]):\n",
    "#     #     for j, x in enumerate(xs):\n",
    "#     #         probs[i, j, :] = agent.predict_proba([[x, v]])[0]\n",
    "\n",
    "#     # Draw policy\n",
    "#     f, ax = plt.subplots(figsize=(7, 7))\n",
    "#     ax.imshow(probs, extent=(env.min_position, env.max_position, -env.max_speed, env.max_speed), aspect='auto')\n",
    "#     ax.set_title('Learned policy: red=left, green=nothing, blue=right')\n",
    "#     ax.set_xlabel('position (x)')\n",
    "#     ax.set_ylabel('velocity (v)')\n",
    "    \n",
    "#     # Sample a trajectory and draw it\n",
    "#     states, actions, _ = generate_session(env, agent)\n",
    "#     states = np.array(states)\n",
    "#     print(np.shape(states))\n",
    "#     ax.plot(states[:, 0, 0], states[:, 0, 1], color='white')\n",
    "    \n",
    "#     # Draw every 3rd action from the trajectory\n",
    "#     for (x, v), a in zip(states[::3, 0], actions[::3]):\n",
    "#         if a == 0:\n",
    "#             plt.arrow(x, v, -0.1, 0, color='white', head_length=0.02)\n",
    "#         elif a == 2:\n",
    "#             plt.arrow(x, v, 0.1, 0, color='white', head_length=0.02)\n",
    "\n",
    "# with gym.make('LunarLander-v2').env as env:\n",
    "#     visualize_mountain_car(env, agent_mountain_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 8\n",
      "n_actions = 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"LunarLander-v2\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50b2b56153843fe85ed1dbfdb9e30d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-99cfdca5625c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-99cfdca5625c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_session' is not defined"
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in trange(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(env, agent) for i in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    \n",
    "    agent_mountain_car.partial_fit(elite_states[:, 0], elite_actions.astype(np.int))\n",
    "        \n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch) + 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.1.56214.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"MountainCar-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent_mountain_car) for _ in range(100)]\n",
    "\n",
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "video_path = video_paths[-1]  # You can also try other indices\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # https://stackoverflow.com/a/57378660/1214547\n",
    "    with video_path.open('rb') as fp:\n",
    "        mp4 = fp.read()\n",
    "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "else:\n",
    "    data_url = str(video_path)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(data_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ (2 pts) Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in Anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ (4 pts) Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * Choose one of [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0) (90+ pts to solve), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) (200+ pts to solve) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules, aside from action spaces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
